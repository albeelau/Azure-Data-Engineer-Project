# Azure-Data-Engineer-Project

In this project, I will explore the dynamic world of retail analytics with Bike Store Customer Analysis and Sales Trends project. Leveraging a Kaggle competition dataset, this project delves into the diverse and intricate landscape of customer behavior and sales trends within a bike store by using Azure data factory and databricks.

1.Why Explore This Project?

-Real-World Relevance: Addressing challenges from a Kaggle competition dataset, this project mirrors the intricacies of real-world business scenarios. 

-End-to-End Solutions: From data ingestion to advanced analytics, witness a complete data engineering and analytics solution. 

-Continuous Learning: Embrace the latest technologies, showcasing a commitment to continuous improvement and staying ahead in the data landscape.


2.Project Highlights:

-Dataset Source: Kaggle Competition - Bike Store Customer Analysis. 

-Objective: Analyze customer behavior and identify sales trends to enhance business insights. 

-Technologies Used: Azure Data Factory: Orchestrating the ETL (Extract, Transform, Load) processes efficiently. 

-Data Lake Gen 2: Storing and managing structured and unstructured data securely. 

-Azure Databricks: Leveraging distributed computing for advanced data analytics and machine learning.


3.What to Expect:

-Data Ingestion and Preparation: Utilizing Azure Data Factory to ingest data from diverse sources into the scalable Azure Data Lake Gen 2 storage.

-Data Exploration and Transformation: Harnessing the power of Azure Databricks for in-depth data exploration, cleaning, and transformation.

-Customer Segmentation: Applying advanced analytics to segment customers based on purchasing behavior and preferences.

-Sales Trends Analysis: Uncovering actionable insights through trend analysis, forecasting, and anomaly detection.

-Visualizations and Reporting: Presenting findings using compelling visualizations to facilitate data-driven decision-making.


# Data Ingestion and Transformation with Azure Databricks
1. Ingest csv files from Azure Data Lake into Azure Databricks by SAS token
![image](https://github.com/albeelau/Azure-Data-Engineer-Project/assets/77976477/36067a9f-4f6e-43bd-a9c9-9f2ddc75f3d9)

2. Read the files on dataframe
![image](https://github.com/albeelau/Azure-Data-Engineer-Project/assets/77976477/f5925afb-4c1f-436d-a054-fa15c1e497a7)

3. Rename the columns
![image](https://github.com/albeelau/Azure-Data-Engineer-Project/assets/77976477/8492349d-f4f7-402d-8ac9-84c90f531cab)


